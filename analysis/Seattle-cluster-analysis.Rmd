---
title: "cluster-analysis"
author: "Chloe, Marykate, Kaddijatou"
date: "04/09/2024"
output: 
  github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)

# Note: Before knitting, make sure you"ve installed the packages used in the
# sections below

packages <- c("knitr", "tidyverse", "readr","devtools", "psych", "cluster", "factoextra",
              "gridExtra", "grid", "here", "rlang", "sf", "urbnthemes", "mclust",
              "dbscan", "data.table", "R.utils", "tidycensus")

## INSTALL PACKAGES
packages <- lapply(packages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    if (x == "urbnthemes") {
      devtools::install_github("UrbanInstitute/urbnthemes")
    } else {
    install.packages(x)
    }
    library(x, character.only = TRUE)}})

set_urbn_defaults(style = "print")

```

Source cluster analysis functions 
```{r}
# Define trial name for modeling run
trial_name <- "seattle_arrests"

```

# Read and Pre-Process Data
# https://data-seattlecitygis.opendata.arcgis.com/datasets/SeattleCityGIS::racial-and-social-equity-composite-index-current/explore?location=47.614467%2C-122.336904%2C12.00
```{r cars}
# Load all Seattle data and reporting boundaries data
SPD_Call_Data <- read_csv("~/Documents/Development/DAT4500/Data/SPD_Call_Data_2023.csv")
SPD_Arrest_Data <- read_csv("~/Documents/Development/DAT4500/Data/SPD_Arrest_Data_2023.csv")
SPD_Stops_Data <- read_csv("~/Documents/Development/DAT4500/Data/SPD_Stops_Data_2023.csv")

SPD_Reporting_Boundries <- read_csv("~/Documents/Development/DAT4500/Data/SPD_Reporting_Boundries_2023.csv")

rd <- st_read("~/Documents/Development/DAT4500/Data/SPD Reporting Beats.geojson",
             stringsAsFactors = FALSE, quiet = TRUE) %>%
             rename(Beat = beat)

rd2 <- st_read("~/Documents/Development/DAT4500/Data/Race_and_Social_Equity_Composite_Index_Current_5634088353558588547.geojson",
             stringsAsFactors = FALSE, quiet = TRUE) 
```

# rename variables

```{r}
SPD_Arrest_Data <- SPD_Arrest_Data %>%
  rename_with(~ gsub(" ", "_", .x), everything()) 

SPD_Arrest_Data
```

```{r}
SPD_Stops_Data <- SPD_Stops_Data %>%
  rename_with(~ gsub(" ", "_", .x), everything()) 

SPD_Stops_Data
```

# Census Data API. Your API key is dfac6b112269655f8addde66c2193b92d61b88d7.
# Documentation on census api https://walker-data.com/census-r/modeling-us-census-data.html
# Data Sources
## Census API: 
### Data was retrieved from the United States Census Bureau using the Census API in R. This API grants access to a range of demographic and socio-economic datasets. For this project, we utilized data from the 2020 Decennial Census.

## Data Retrieval Process
## Step 1: 
###Insert the API key obtained from the Census Bureau.

```{r}
census_api_key("dfac6b112269655f8addde66c2193b92d61b88d7", install = TRUE, overwrite=TRUE)
```


## Step 2: 
### Load Seattleâ€™s population data by race for the year 2020.

####  https://api.census.gov/data/2020/dec/pl/variables.html
####  Washington GEOID = 53
####  P1_003N: White alone
####  P2_002N: Hispanic 
####  P1_004N: Black or African American alone
####  P1_005N: American Indian and Alaska Native alone
####  P1_006N: Asian alone
####  P1_007N: Native Hawaiian and Other Pacific Islander alone
####  P1_008N: Some Other Race alone
####  P1_009N: Two or More Races

```{r}
# Load the data for Seattle's population by specific races using 2020 Decennial Census
seattle_census_data <- get_decennial(
  geography = "tract",
  variables = c("P1_003N","P2_002N", "P1_004N", "P1_005N", "P1_006N", "P1_007N", "P1_008N", "P1_009N"),
  state = "WA",
  county = "King",
  region = "Seattle",
  year = 2020
)

head(seattle_census_data)
```
# Remane value to population 

```{r}
seattle_census_data <- seattle_census_data %>%
  rename(population = value)
```

# Translate the varibles to the actual race

```{r}
seattle_census_data <- seattle_census_data %>%
  mutate(race = recode(variable,
                       P1_003N = "White",
                       P1_004N = "Black or African American",
                       P1_005N = "American Indian or Alaska Native",
                       P1_006N = "Asian",
                       P1_007N = "Native Hawaiian or Other Pacific Islander",
                       P1_008N = "Some Other Race alone", #Some Other Race alone
                       P1_009N = "Two or More Races",# Two or More Races
                       P2_002N = "Hispanic or Latino"))
seattle_census_data
```
# Compute total population
```{r}
# Group by race and calculate total population
race_population <- seattle_census_data %>%
  group_by(race) %>%
  summarize(total_population = sum(population))

race_population
```


# Merge the census data with the Seattle geographic data
```{r}
seattle_census_data <- seattle_census_data  %>%
  filter(GEOID %in% rd2$GEOID) %>%
  left_join(rd2[, c("GEOID", "geometry")], by = "GEOID")
```

# Combine census data 
```{r}
# Convert the data to an sf object
 seattle_census_data <- st_as_sf(seattle_census_data)

seattle_census_data 
```

```{r}
# Aggregate population by GEOID and race
aggregated_census_data <- seattle_census_data %>%
  group_by(geometry, race) %>%
  summarise(population = sum(population, na.rm = TRUE), .groups = 'drop') %>%
  st_cast("MULTIPOLYGON")


head(aggregated_census_data)

```


```{r}
# Spatial join using st_join which defaults to using st_intersects
combined_data <- aggregated_census_data  %>%
  st_join(rd, by = "geometry")

head(combined_data)
```
# group SPD call data by Beats, join SPD call with stop and arrest data
```{r}
SPD_Combined_Data <- SPD_Call_Data %>%
  group_by(Beat) %>%
  summarise(Calls = n()) %>%
  left_join(SPD_Arrest_Data %>% group_by(Beat) %>% summarise(Arrests = n()), by = "Beat") %>%
  replace_na(list(Arrests = 0, Stops = 0)) %>%   left_join(SPD_Stops_Data %>% group_by(Beat) %>% summarise(Stops = n()), by = "Beat") %>% # Replace NA with 0 in case there are no records for some Beats in Arrests or Stops
  left_join(combined_data)
write_csv(SPD_Combined_Data, "SPD_Combined_Data.csv")

head(SPD_Combined_Data)

```
